<!DOCTYPE html>
<html
  lang="zh-cn"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元 - 区块大全
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="佚名" /><meta name="description" content="很多企业都能做出GPT-4。" />

  <meta name="keywords" content="区块大全, 区块链, 区块链资讯, 区块链快讯, 区块链新闻, 比特币行情" />






<meta name="generator" content="Hugo 0.120.4" />


<link rel="canonical" href="/post/54764/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.d8d87b982993a745e5e7b6a6cbf257be8c3e82aab5e485f0908ad7e6c3501ab2.css" integrity="sha256-2Nh7mCmTp0Xl57amy/JXvow&#43;gqq15IXwkIrX5sNQGrI=" media="screen" crossorigin="anonymous">







<meta property="og:title" content="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元" />
<meta property="og:description" content="很多企业都能做出GPT-4。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/54764/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-07-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-07-11T00:00:00+00:00" />

<meta itemprop="name" content="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元">
<meta itemprop="description" content="很多企业都能做出GPT-4。"><meta itemprop="datePublished" content="2023-07-11T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-07-11T00:00:00+00:00" />
<meta itemprop="wordCount" content="8017">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"/>
<meta name="twitter:description" content="很多企业都能做出GPT-4。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">区块大全</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    


    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/" class="logo">
    
      区块大全
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      佚名
    
  </div>

  <div class="post-meta-time">
    <time datetime="2023-07-11">
      2023-07-11
    </time>
  </div>

  


  <div class="post-meta__right">
    <span class="post-meta-more">
        约 8017 字 -
        预计阅读 17 分钟
      </span>

    <div class="post-meta-category">
        <a href="/categories/%E5%85%B6%E5%AE%83%E6%96%87%E7%AB%A0/"> 其它文章 </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">币安网</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/binance?ref=githubio">注册链接</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/binance?ref=githubio">币安是全球领先的区块链生态系统，推出了一系列产品，其中包括最大的加密货币交易平台。我们的使命是在未来成为全球性加密货币基础架构供应商。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">欧易OKX</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/okx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/okx?ref=githubio">欧易是全球著名的数字资产交易平台之一，主要面向全球用户提供比特币、莱特币、以太币等数字资产的币币和衍生品交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">HTX火币</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/htx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/htx?ref=githubio">火币全球专业站，是火币集团旗下服务于全球专业交易用户的创新数字资产国际站，致力于发现优质的创新数字资产投资机会。</a>
            </td>
        </tr>
    </tbody>
</table>
<p>来源：<a href="http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&amp;mid=2652350213&amp;idx=2&amp;sn=dca4f89f694fb5f4bde888f9c95303b2&amp;chksm=f124d3f4c6535ae2f4ef9d850753624923bd22205588aaed3c6f087f00f4d3bcb4d95c545398#rd">“新智元”（ID：AI_era）</a></p>
<p>就在刚刚，OpenAI的GPT-4又被业内人士「开源」了！</p>
<p>其中包括GPT-4的架构、训练和推理的基础设施、参数量、训练数据集、token数、成本、混合专家模型（Mixture of Experts，MoE）等非常具体的参数和信息。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/0a36pd1ffqnsep0" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>尤其是，在不同工程背后，OpenAI究竟是怎样权衡的。以及在巨型模型推理时，如何跨越其中最大的瓶颈。</p>
<p>如此重磅的爆料，出自何许人也？</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/vnic2gpj6du8iqw" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>文章作者，是SemiAnalysis的两位名叫Dylan Patel和Gerald Wong的撰稿人。</p>
<p>值得一提的是，此前曾在业内引起轩然大波的谷歌内部文件泄漏事件（「我们没有护城河，OpenAI也没有」），作者之一同样是Dylan Patel。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/3pbkcv9yr3u2mdt" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>而DeepMind CEO Hassabis近日在外媒The Verge的采访中，确认了这份谷歌工程师泄漏文件的真实性。</p>
<p>可见，Dylan Patel的确有一些特殊渠道，这就让今日这份爆料的真实性又提高了几分。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/6fihp30c3o9vn5m" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>出门问问CEO李志飞对此也发表了感言</p>
<h2 id="很多企业都能做出gpt-4">很多企业都能做出GPT-4</h2>
<p>在爆料文章作者看来，OpenAI之所以不open，不是为了确保人类不被AI毁灭，而是因为他们构建的东西是可复制的。</p>
<p>他甚至预计，未来所有中国和美国的互联网大厂或者AI头部初创企业，都会有能力构建出和GPT-4一样，甚至是超过GPT-4的模型。</p>
<p>但他同时也承认，GPT-4是OpenAI的伟大杰作。它凝结了工程师的匠心设计，复杂的构架和各种巧妙的工程上的取舍。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/by591av9zszz98s" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>而OpenAI最持久的护城河，是他们拥有真实用户的使用反馈，业内最顶尖的工程人才，以及先发优势带来的持续领先地位。</p>
<h2 id="模型框架">模型框架</h2>
<p>首先爆料作者认为，GPT-4在120层中总共包含了1.8万亿参数，而GPT-3只有约1750亿个参数。</p>
<p>也就是说，GPT-4的规模是GPT-3的10倍以上。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/n4ynk4fcsvsh7oo" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>此前网上流传的说法是，GPT-4的参数是1万亿，看来离实际情况还是低估了</p>
<p>为了保持合理的成本，OpenAI采用了MoE模型来进行构建。</p>
<p>具体而言，GPT-4拥有16个专家模型，每个MLP专家大约有1110亿个参数。其中，有两个专家模型被用于前向传播。</p>
<p>虽然文献中大量讨论了选择每个token指向哪些专家的高级算法，但是据说，OpenAI用于GPT-4的算法，其实非常简单。</p>
<p>此外，模型中还有大约550亿个参数，被用做注意力机制的共享。</p>
<p>在每次的前向传播推理（生成一个token）中，GPT-4只需要使用大约2800亿参数和560TFLOPs。</p>
<p>这与很多纯密集模型每次前向传播需要大约1.8万亿参数和3700TFLOPs形成了鲜明的对比。</p>
<h2 id="数据集的构成">数据集的构成</h2>
<p>OpenAI用13万亿的token训出了GPT-4。</p>
<p>这个数据集不单单是包含了13万亿的token，而且因为没有高质量的token，这个数据集还包含了许多个epoch。</p>
<p>在Scale AI和数据集内部，还包含了数百万行的指令微调数据。</p>
<p>不过爆料作者说，在这些RLHF数据上，他们并没有找到太多信息。</p>
<p>在预训练阶段的上下文长度达到了8K（seqlen），而32k的版本是基于预训练后的8K版本微调而来的。</p>
<p>批大小在集群中是几天之内逐渐增加的，最终OpenAI使用的批大小为6000万。</p>
<p>当然，这「只是」每个750万token的专家模型的大小，因为不是每个专家模型都会看到全部的token。</p>
<h2 id="并行策略">并行策略</h2>
<p>并行策略对于A100GPU是相当重要的。</p>
<p>OpenAI采用了8路张量并行，因为NVLink最高只支持这么多。</p>
<p>但除此之外，爆料作者听说OpenAI采用15路并行管线。</p>
<p>理论上，考虑到数据通信和计算时间，15个管线就有些多了。</p>
<p>但是因为受到内存容量的限制，这么多的管线就是有意义的了。</p>
<p>当纯管线和张量并行时，每个GPU的FP16参数大约是30GB。</p>
<p>但是一旦加上了KV缓存和成本，如果OpenAI使用的GPU大部分是40GB的A100，那这样的构架在理论上就是有意义的。</p>
<p>可能OpenAI使用的是ZeRo Stage 1，并且可能使用的是块级FSDP或者是混合共享数据并行。</p>
<p>为什么他们没有使用FSDP的全模型呢？可能是因为过高的通信成本。</p>
<p>虽然OpenAI大多数节点之间都有高速网络，但是没有覆盖所有的节点。</p>
<p>其中，至少有一些集群的连接带宽会比其他的集群低很多。</p>
<p>但是作者表示，他并不是太明白OpenAI在如此高的管线并行度下，如何避免在每批中产生如下图这样的「泡泡」（huge bubbles），很有可能OpenAI就是生生地抗下了这些成本。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/2qbnwrqdp22nlp1" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<h2 id="训练成本">训练成本</h2>
<p>OpenAI训练GPT-4的FLOPS约为2.15e25，在大约25000个A100上训练了90到100天，利用率在32%到36%之间。</p>
<p>这种极低的利用率，部分原因是故障数量过多，这就会导致需要重新从之前的检查点开始训练。比如上面提到的气泡成本。</p>
<p>这种情况浪费的训练成本极高。</p>
<p>另一个原因是这么多GPU之间的all-reduce非常昂贵。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/rvsc8zi81niko2z" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>此图表假设，无法融合每个操作、注意力机制所需的内存带宽、硬件开销相当于参数读取，都会导致效率低下。实际上，即使使用优化的库，比如英伟达的FasterTransformrmer库，总开销甚至还会更大</p>
<p>爆料作者怀疑，如果这种集群实际上是一群具有较弱网络连接的较小集群构成的，那么集群不同部分之间的非阻断（non-block）连接速度为800G/1.6T，但这些部分之间的连接速度仅为200G/400G。</p>
<p>如果OpenAI云计算的成本是差不多1美元/每A100小时的话，那么在这样的条件下，训练成本大约是6300万美元。</p>
<p>这还不包括所有的实验、失败的训练和其他成本，比如数据收集、RLHF、人力成本等。</p>
<p>如果考虑到刚刚说的这些因素，真实成本要高得多的多。</p>
<p>此外，这还得是在能别人买得到芯片/网络/数据中心，承担资本支出组建了这些系统，并将它们租给OpenAI的前提下。</p>
<p>但是放到今天，在2美元/每H100小时的条件下，预训练可以在大约8,192个H100上进行，只需要55天，费用为2150万美元。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/4ackrtpj10p11p7" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>上图显示了一些已公开的先进模型各自的参数数量和token。图中的线是谷歌DeepMind的Chinchilla缩放观测值（平滑了较大的误差条），线上的每一点都显示了使用该参数和token数训练模型所需的理论FLOPS</p>
<p>不过，爆料作者称到今年年底，至少将会有9个公司拥有超过上述大小的H100集群。</p>
<p>虽然并非所有这些公司都会将它们全部用于单个模型训练，但如果有公司这样做的话，他们将拥有比GPT-4更大的模型。</p>
<p>比如Meta到今年年底将拥有超过100,000个H100，但其中相当一部分将分布在自己的数据中心进行推理。</p>
<p>但是它最大的单个集群仍将超过25,000个H100。</p>
<p>总之，到今年年底，许多公司都会拥有足够的算力资源，来训练GPT-4大小的模型。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/fsl3bzs3h0n5y1r" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>本表是在英伟达A100上训练模型的理论最佳成本，没有考虑所需的人力、ML Ops工具、数据收集/预处理、故障恢复、one-shot/few-shot学习示例、推理等，许多部分的成本高得惊人</p>
<h2 id="混合专家模型方面的权衡">混合专家模型方面的权衡</h2>
<p>MoE（混合专家模型）是一种在推理过程中减少参数量的很好方法，虽然同时会增加参数量。</p>
<p>但是这对于每个训练标记来编码更多信息是必要的，因为获取足够高质量的标记非常困难。</p>
<p>如果OpenAI真的想追求最佳性能，他们需要训练两倍的token才能达到。</p>
<p>话虽如此，OpenAI还是做出了不少的取舍。</p>
<p>例如，在推理过程中处理MoE非常困难，因为模型的每个部分并不在每个token生成时都被使用。</p>
<p>这意味着有些部分可能处于休眠状态，而其他部分在工作。</p>
<p>当为用户提供服务时，这种情况会大大降低利用率。</p>
<p>研究人员已经证明，使用64-128个专家模型比使用16个专家模型能够获得更好的损失情况，但这仅仅是研究结果。</p>
<p>采用相对比较少的专家模型的原因很多，OpenAI选择16个专家的原因之一是因为在许多任务上更多的专家模型很难泛化。</p>
<p>使用更多的专家模型也更难实现收敛。</p>
<p>在如此庞大的训练过程中，OpenAI选择在专家模型数量上反而更为保守。</p>
<p>此外，使用较少的专家模型还有助于他们的推理基础架构。在切换到混合专家模型推理架构时，存在各种困难的取舍和权衡。</p>
<p>爆料作者从对LLM推理的基本取舍开始讨论，然后再讨论OpenAI面临的问题和他们所做的选择。</p>
<h2 id="推理权衡">推理权衡</h2>
<p>在介绍推理权衡之前，顺带提一下，爆料者与所有的LLM公司交谈过后，发现英伟达的FasterTransformer推理库非常糟糕，TensorRT更是如此。</p>
<p>这意味着，如果英伟达不修改，人们还需要从头开始创建自己的解决方案。</p>
<p>推理大型语言模型有三个主要的权衡，即批大小（同时处理用户数）维度和使用的芯片数量，具体如下：</p>
<p><strong>1. 延迟</strong></p>
<p>模型必须在合理的延迟时间内做出响应。谁也不想在聊天APP中等待几秒钟才开始收到输出。预填（输入token）和解码（输出token）的处理时间各不相同。</p>
<p><strong>2. 吞吐量</strong></p>
<p>模型必须以每秒输出一定数量的token。人类大约需要每秒30个token。对于其他各种用例，较低和较高的吞吐量都可以接受。</p>
<p><strong>3. 利用率</strong></p>
<p>运行模型的硬件必须实现高利用率，否则成本过高。虽然更高的延迟和较低的吞吐量，可以用来将更多用户请求组合在一起，从而实现更高的利用率，但也会增加难度。</p>
<p>LLM推理的关键是平衡内存带宽和计算这两个要点。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/asp56d7zk65f7zh" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>LLM理论带宽要求：经假设可得出，在iPhone 14上可跑的最大模型大小为~10亿个FP16参数，或~40亿个int4参数，这是基于智能手机的LLM的基本限制，任何更大的模型会无法被采用</p>
<p>简单来讲，每个参数都必须被读取，并且与之相关的有2个FLOP。</p>
<p>因此，大多数芯片的比率（H100 SXM仅有3TB/s内存带宽，但FP8有2,000 TFLOP/s）在批大小为1的推理中完全是不平衡的。</p>
<p>如果只有一个用户（批大小为1），那么在每次生成token时，为了读取每个参数所需的内存带宽，会主要占据推理时间，而计算时间几乎可以忽略不计。</p>
<p>为了将大型语言模型高效地扩展到多个用户，批处理大小必须超过1。多个用户将参数读取成本分摊。例如，在批大小为256/512时，每个字节的内存读取可以获得512 FLOP/s或1024 FLOP/s。</p>
<p>这个比率更接近H100的内存带宽与FLOPS之间的平衡。这有助于实现更高的利用率，但代价是更高的延迟。</p>
<p>很多人认为内存容量是LLM推理的一个主要瓶颈，因为大型模型需要多个芯片进行推理，而较高的内存容量意味着它们可以适应较少的芯片。</p>
<p>然而，实际上更好的方法是使用更多的芯片，以便将延迟降低，增加吞吐量，并且可以使用更大的批大小以实现更高的利用率。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/eq2ge5fd34l8w1f" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<h2 id="gpt-4推理权衡和基础设施"><strong>GPT-4推理权衡和基础设施</strong></h2>
<p>以上所提到的，对GPT-4推理来说非常困难。但是作为一个MoE模型，再次引入了一系列全新的困难。</p>
<p>每个生成token的前向传递可以路由到不同的专家组。这对在较大的批大小下的吞吐量、延迟和利用率之间的权衡造成了困扰。</p>
<p>OpenAI的GPT-4有16个专家，每个前向传递路由到其中2个专家。</p>
<p>这意味着如果批大小为8，每个专家的参数读取可能只有批大小为1。</p>
<p>更糟糕的是，这可能意味着一个专家的批大小为8，而其他专家的批大小为4、1或0。</p>
<p>每个生成token，路由算法都会将前向传递发送到不同的方向，导致token之间的延迟和专家批大小显著变化。</p>
<p>推理基础设施是OpenAI选择较少数量的专家的主要原因之一。如果他们选择更多的专家，内存带宽会成为推理的瓶颈。</p>
<p>OpenAI的推理集群通常可以达到4k+的批大小，这意味着即使在专家之间实现最佳的load平衡，专家的批大小也只有大约500左右。这需要非常大量的使用才能实现。</p>
<p>爆料者称，我们了解到OpenAI在一个由128个GPU组成的集群上进行推理。他们在多个数据中心和地理位置上都有多个这样的集群。</p>
<p>推理采用8路张量并行和16路管线并行。每个由8个GPU组成的节点只有约130B的参数，或者在FP16下每个GPU不到30GB，在FP8/int8下不到15GB。</p>
<p>这样可以在40GB的A100上运行推理，只要所有批的KV缓存大小不会过大。</p>
<p>不同节点上的包含不同专家的层不会被分割，因为那样会导致网络流量过于不规则，而在每个生成token之间重新计算KV缓存的代价太高。</p>
<p>对于未来的MoE模型扩展和条件路由，最大的困难是如何处理KV缓存的路由。</p>
<p>模型的层数为120，所以可以简单地将它们分配给15个不同的节点，但是因为第一个节点需要进行数据加载和嵌入，所以在推理集群的主节点上放置较少的层是有意义的。</p>
<p>此外，有一些关于「推测解码」（后续）的传闻，这也解释了为什么主节点需要包含较少的层。</p>
<h2 id="推理成本">推理成本</h2>
<p>与拥有1750亿参数的Davinchi模型相比，GPT-4的成本是其3倍，尽管其前馈参数只增加了1.6倍。</p>
<p>这主要是因为GPT-4需要更大的集群，并且实现的利用率更低。</p>
<p>作者认为，在128个A100上推理GPT-4的8k序列长度每1,000个标记的成本为0.0049美元，而在128个H100上推理GPT-4的8k序列长度每1,000个标记的成本为0.0021美元。</p>
<p>需要注意的是，这是假设有相当高的利用率，并保持较高批大小的情况下。</p>
<p>但很明显，OpenAI有时的利用率非常低。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/oqhwsyfyripsuyq" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>对此作者假设，OpenAI会在低峰时段关闭集群，重新配置节点，恢复训练较小的测试模型，并尝试各种新技术，从而降低推理成本。</p>
<p>如果OpenAI不这样做，他们的利用率会更低，而成本也将增加一倍以上。</p>
<h2 id="多查询注意力">多查询注意力</h2>
<p>除此之外，OpenAI也在使用多查询注意力（Multi-Query Attention，MQA）。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/vit0bza9uy490p9" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>论文地址：https://arxiv.org/pdf/1911.02150.pdf</p>
<p>简而言之，只需要一个注意力头，并且可以显著减少KV缓存的内存占用。</p>
<p>即便如此，32k长度的GPT-4肯定无法在40GB的A100上运行，而8k的最大批大小也有上限。</p>
<h2 id="连续批处理">连续批处理</h2>
<p>OpenAI实现了可变批大小和连续批处理。</p>
<p>这样做可以允许一定程度的最大延迟，并优化推理成本。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/rmbcnyak7hbhksb" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p><img src="https://img.bibiqing.com/news/2023/0711/jyzfo2c3r5rkd98" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<h2 id="推测解码speculative-decoding">推测解码（Speculative Decoding）</h2>
<p>爆料称，OpenAI在GPT-4的推理过程中使用了「推测解码」，这其中还有100%的不确定性。</p>
<p>token到token的延迟变化，以及在进行简单的检索任务和更复杂的任务时差异，似乎表明这一点是可能的，不过还是有太多的变量无法确定。</p>
<p>在此，爆料者通过DeepMind的一项研究「Accelerating LLM Inference with Staged Speculative Decoding」中的文本，进行了适当修改/添加一些细节，进行了解释。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/sozrm88az7nonm0" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>使用LLM通常分为两个阶段。</p>
<p>首先是预填充（prefill），将提示文本输入模型中以生成KV缓存和第一个输出的对数几率（可能的token输出的概率分布）。这个过程通常很快，因为整个提示文本可以并行处理。</p>
<p>第二个阶段是解码（decoding）。从输出的对数几率中选择一个token，并将其反馈到模型中，模型将生成下一个token的对数几率。重复这个过程，直到生成所需数量的token。</p>
<p>由于解码必须按顺序进行，每次都需要将权重流通过计算单元以生成单个token。因此当以小量批运行时，这个第二阶段的计算密集度（即计算FLOP/内存带宽的字节数）非常低。因此，解码通常是自回归生成中最昂贵的部分。</p>
<p>这就是为什么OpenAI的API调用中，输入token比输出token便宜得多的原因。</p>
<p>「推测解码」的基本思想是使用一个更小、更快的草案模型提前解码多个token，然后将它们作为一个批输入到预测模型中。</p>
<p>如果草案模型的预测是正确的，即更大的模型也同意这些预测，那么可以使用单个批解码多个token，这样可以节省大量的内存带宽和时间。</p>
<p>然而，如果更大的模型拒绝了草案模型预测的token，则剩余的批将被丢弃，算法自然会恢复到标准的逐个token解码。</p>
<p>「推测解码」可能还伴随着拒绝抽样的方案，以从原始分布中进行采样。值得注意的是，这仅在带宽是瓶颈的小批设置中有用。</p>
<p>「推测解码」以计算换取带宽，而成为一个有吸引力的性能工程目标有两个关键原因：</p>
<p>首先，它不会降低模型质量。其次，它提供的性能改进通常与其他方法正交，因为其性能来自于将「顺序执行」转换为「并行执行」。</p>
<p>当前的推测方法为批预测的单独序列。然而，这种方法不能很好地拓展到大量的批，或低草案模型对齐上。</p>
<p>直观地说，两个模型在连续长序列的token上达成一致的概率呈指数级低，这意味着随着算术密度的增加，推测解码的收益会迅速减少。</p>
<p>爆料者认为，如果OpenAI使用「推测解码」，他们可能只在大约4个token的序列中使用。</p>
<p>顺便提一句，有关OpenAI阉割，而导致GPT-4质量降低的整个阴谋，可能只是因为他们让预测模型接受了「推测解码」模型的低概率序列。</p>
<p>另外有人推测，Bard也使用了「推测解码」，因为谷歌在将整个序列发送给用户之前会等待其完全生成，但在爆料者认为，这种猜测是完全不正确的。</p>
<h2 id="视觉多模态">视觉多模态</h2>
<p>视觉多模态能力是GPT-4中最不令人印象深刻的部分，至少与领先的研究相比是如此。</p>
<p>当然，现在还没有人将多模态LLM的研究成果商业化。</p>
<p>爆料者称，它是一个独于文本编码器的视觉编码器，还有交叉注意力，架构类似于Flamingo，并在GPT-4 1.8T上增加了更多参数。</p>
<p>GPT-4多模态能力是在文本预训练之后，又用大约2万亿token进⾏了微调。</p>
<p>据称，在视觉模型上，OpenAI原本希望从头开始训练，但因其不够成熟，无奈从文本训练模型进行微调。</p>
<p>而下一代模型GPT-5，其训练应该从零开始训练视觉模型，并且能够生成图像，甚至生成音频。</p>
<p>这样的视觉能力主要目的之一，让自主智能体能够阅读网页，并转录图像，视频中的内容。</p>
<p>值得一提的是，OpenAI用来训练多模态模型的数据包括：「联合数据」（LaTeX/文本）、网页屏幕截图、YouTube视频（采样帧，以及运行Whisper获取字幕）。</p>
<p>关于LLM的过度优化，一个有趣的事实是视觉模型的IO成本不同于文本模型。在视觉模型中，数据加载IO大约是文本模型的150倍。</p>
<p><img src="https://img.bibiqing.com/news/2023/0711/h6ed6fje0qsmm81" alt="GPT-4内幕大泄露，1.8万亿巨量参数，13万亿token训练，斥资6300万美元"></p>
<p>视觉模型的IO成本很低</p>
<p>视觉模型中的每个token 600字节，文本是4字节/token。</p>
<p>因此这需要在图像压缩方面做很多工作。这对于硬件供应商来说极为重要，因为他们正在围绕LLM的用例和比率优化2-3年后的硬件。</p>
<p>他们可能会发现自己身处的世界中，每个模型都具有强大的视觉和音频功能。</p>
<p>他们可能会发现自己的架构适应性会很差。</p>
<p>总的来说，架构肯定会超越我们今天看到的基于文本简化的密集模型，和MoE模型。</p>
<h3 id="参考资料">参考资料</h3>
<p><a href="https://www.semianalysis.com/p/gpt-4-architecture-infrastructure">https://www.semianalysis.com/p/gpt-4-architecture-infrastructure</a></p>
<table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Gate芝麻开门</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/gateio?ref=githubio">平台介绍</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/gateio?ref=githubio">Gate.io芝麻开门创立于2013年，是全球真实交易量TOP10的加密货币交易平台，向全球数千万用户提供安全可靠、真实透明的数字资产交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bitget</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bitget?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bitget?ref=githubio">Bitget的背后是一群区块链技术的早期接受者，也是区块链未来发展的信仰者，一直致力于提供安全、一站式的交易解决方案，帮助用户更聪明地交易。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bybit</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bybit?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bybit?ref=githubio">Bybit通过数字资产与传统金融的结合，引领数字资产的生态发展。提供一流的流动性，致力于打造业内最安全、公平、高效及人性化的交易服务平台。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">派网</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/pionex?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/pionex?ref=githubio">派网提供多样化的量化交易机器人，用户可依照自身交易需求和策略选择最适合的机器人。 同时派网也提供合约交易与合约网格机器人，给予更方便的合约交易体验。</a>
            </td>
        </tr>
    </tbody>
</table>

        </div>

        
        



        
        


        <footer class="post-footer">
          


          
          <nav class="post-nav">
            
              <a class="prev" href="/post/54808/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">FTX 崩塌半年之后：跌落神坛的 Solana 能否重拾光环</span>
                <span class="prev-text nav-mobile">上一篇</span>
              </a>
            
              <a class="next" href="/post/54740/">
                <span class="next-text nav-default">IOSG Ventures：全面解读社区驱动的赏金和审计市场</span>
                <span class="prev-text nav-mobile">下一篇</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      
        
      


      
      


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">文章目录</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#很多企业都能做出gpt-4">很多企业都能做出GPT-4</a></li>
    <li><a href="#模型框架">模型框架</a></li>
    <li><a href="#数据集的构成">数据集的构成</a></li>
    <li><a href="#并行策略">并行策略</a></li>
    <li><a href="#训练成本">训练成本</a></li>
    <li><a href="#混合专家模型方面的权衡">混合专家模型方面的权衡</a></li>
    <li><a href="#推理权衡">推理权衡</a></li>
    <li><a href="#gpt-4推理权衡和基础设施"><strong>GPT-4推理权衡和基础设施</strong></a></li>
    <li><a href="#推理成本">推理成本</a></li>
    <li><a href="#多查询注意力">多查询注意力</a></li>
    <li><a href="#连续批处理">连续批处理</a></li>
    <li><a href="#推测解码speculative-decoding">推测解码（Speculative Decoding）</a></li>
    <li><a href="#视觉多模态">视觉多模态</a>
      <ul>
        <li><a href="#参考资料">参考资料</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  

<a href="https://www.okbtc.cn/binance?ref=githubio" class="iconfont">
  <img src="/image/logo/binance.png" width="36px" height="36px" alt="binance">
</a>

<a href="https://www.okbtc.cn/okx?ref=githubio" class="iconfont">
  <img src="/image/logo/okx.png" width="36px" height="36px" alt="okx">
</a>

<a href="https://www.okbtc.cn/htx?ref=githubio" class="iconfont">
  <img src="/image/logo/htx.png" width="36px" height="36px" alt="htx">
</a>

<a href="https://www.okbtc.cn/gateio?ref=githubio" class="iconfont">
  <img src="/image/logo/gateio.png" width="36px" height="36px" alt="gateio">
</a>

<a href="https://www.okbtc.cn/bitget?ref=githubio" class="iconfont">
  <img src="/image/logo/bitget.png" width="36px" height="36px" alt="bitget">
</a>

<a href="https://www.okbtc.cn/bybit?ref=githubio" class="iconfont">
  <img src="/image/logo/bybit.png" width="36px" height="36px" alt="bybit">
</a>

<a href="https://www.okbtc.cn/pionex?ref=githubio" class="iconfont">
  <img src="/image/logo/pionex.png" width="36px" height="36px" alt="pionex">
</a>



</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    2023
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        coin
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.5e8c82c5ae3f71b40f78c4ff8ea351326a65ddf5771f76c10c6fc7d09808332d.js" integrity="sha256-XoyCxa4/cbQPeMT/jqNRMmpl3fV3H3bBDG/H0JgIMy0=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  











<script>
  var remark_config = {
    host: 'https:\/\/remark42.example.com',
    site_id: 'remark',
    components: [
	    'embed',
    ],
  }
  !function(e,n){for(var o=0;o<e.length;o++){var r=n.createElement("script"),c=".js",d=n.head||n.body;"noModule"in r?(r.type="module",c=".mjs"):r.async=!0,r.defer=!0,r.src=remark_config.host+"/web/"+e[o]+c,d.appendChild(r)}}(remark_config.components||["embed"],document);
</script>







  </body>
</html>
