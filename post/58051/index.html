<!DOCTYPE html>
<html
  lang="zh-cn"
  itemscope
  itemtype="http://schema.org/WebPage"
>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <title>
          6000字解读：当前大语言模型LLM研究的10大挑战 - 区块大全
        </title>
    

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="佚名" /><meta name="description" content="你最感兴趣的研究方向是什么？" />

  <meta name="keywords" content="区块大全, 区块链, 区块链资讯, 区块链快讯, 区块链新闻, 比特币行情" />






<meta name="generator" content="Hugo 0.120.4" />


<link rel="canonical" href="/post/58051/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.d8d87b982993a745e5e7b6a6cbf257be8c3e82aab5e485f0908ad7e6c3501ab2.css" integrity="sha256-2Nh7mCmTp0Xl57amy/JXvow&#43;gqq15IXwkIrX5sNQGrI=" media="screen" crossorigin="anonymous">







<meta property="og:title" content="6000字解读：当前大语言模型LLM研究的10大挑战" />
<meta property="og:description" content="你最感兴趣的研究方向是什么？" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/58051/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-08-30T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-08-30T00:00:00+00:00" />

<meta itemprop="name" content="6000字解读：当前大语言模型LLM研究的10大挑战">
<meta itemprop="description" content="你最感兴趣的研究方向是什么？"><meta itemprop="datePublished" content="2023-08-30T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-08-30T00:00:00+00:00" />
<meta itemprop="wordCount" content="7782">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="6000字解读：当前大语言模型LLM研究的10大挑战"/>
<meta name="twitter:description" content="你最感兴趣的研究方向是什么？"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




  </head>
  <body>
    <div id="back-to-top"></div>

    <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">区块大全</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          
        
      </li>
    

    
  </ul>
</nav>


    
      






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

    

    

    


    <header id="header" class="header">
      <div class="logo-wrapper">
  <a href="/" class="logo">
    
      区块大全
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="/categories/">分类</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

    </header>

    <div id="mobile-panel">
      <main id="main" class="main bg-llight wallpaper">
        <div class="content-wrapper">
    <div id="content" class="content">
      <article class="post">
        
        <header class="post-header">
          <h1 class="post-title">6000字解读：当前大语言模型LLM研究的10大挑战</h1>
          

          <div class="post-meta">
  <div class="post-meta-author">
    by
      佚名
    
  </div>

  <div class="post-meta-time">
    <time datetime="2023-08-30">
      2023-08-30
    </time>
  </div>

  


  <div class="post-meta__right">
    <span class="post-meta-more">
        约 7782 字 -
        预计阅读 16 分钟
      </span>

    <div class="post-meta-category">
        <a href="/categories/%E5%85%B6%E5%AE%83%E6%96%87%E7%AB%A0/"> 其它文章 </a>
          
      </div>


    
    


    
    
  </div>
</div>

        </header>

        
        <div class="post-content">
          <table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">币安网</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/binance?ref=githubio">注册链接</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/binance?ref=githubio">币安是全球领先的区块链生态系统，推出了一系列产品，其中包括最大的加密货币交易平台。我们的使命是在未来成为全球性加密货币基础架构供应商。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">欧易OKX</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/okx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/okx?ref=githubio">欧易是全球著名的数字资产交易平台之一，主要面向全球用户提供比特币、莱特币、以太币等数字资产的币币和衍生品交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">HTX火币</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/htx?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/htx?ref=githubio">火币全球专业站，是火币集团旗下服务于全球专业交易用户的创新数字资产国际站，致力于发现优质的创新数字资产投资机会。</a>
            </td>
        </tr>
    </tbody>
</table>
<p><strong>作者：Chip Huyen</strong></p>
<p><strong>翻译：</strong> <a href="https://mp.weixin.qq.com/s/FDWn6JkOi_nDaK59ogeBIw">阿法兔</a></p>
<p><strong>来源链接</strong> ：https://huyenchip.com/2023/08/16/llm-research-open-challenges.html</p>
<p>让大语言模型变得更完善这个目标，是我一生中，第一次见到这么多的聪明人，同时在为一个共同目标而努力。在同众多业界和学术界人士交流后，我注意到出现了十大研究方向。目前受到关注最多的两个方向是Hallucinations（输出幻觉） 和 Context Learning。</p>
<p>而对我自己来说，最感兴趣的是下面列出的第 3 个方向（Multimodality多模态数据模式）、第 5 个方向（New architecture 新架构）和第 6 个方向（GPU alternatives开发GPU替代的解决方案）</p>
<blockquote>
<p>LLM 研究的十大公开挑战<br>
减少并评估输出输出（虚构信息）<br>
优化上下文长度和上下文构建<br>
融合其他数据形式<br>
提升语言模型的速度和成本效益<br>
设计新的模型架构<br>
开发替代GPU的解决方案<br>
提升代理（人工智能）的可用性<br>
改进从人类偏好中学习的能力<br>
提高聊天界面的效率<br>
构建用于非英语语言的语言模型</p>
</blockquote>
<h2 id="1-减少和评估幻觉">1. 减少和评估幻觉</h2>
<p>输出环境是一个已经被大量讨论过的话题，所以这里我会长话短说。当人工智能模型胡编乱造时，就会产生幻觉。对于许多创意用例来说，幻觉属于功能的一种。然而，对于大多数应用场景来说，幻觉属于一种错误。最近，我与 Dropbox、Langchain、Elastics 和 Anthropic 的专家共同参加了一个关于 LLM 的专题讨论会，在他们看来，企业在实际生产中，应用 LLM 需要克服的首要障碍就是幻觉输出。</p>
<p>降低模型的幻觉输出和制定评估幻觉输出的指标，是一个蓬勃发展的研究课题，目前很多初创公司都在关注这个问题。还有一些技巧可以减少幻觉输出的概率，例如在提示词中添加更多上下文、CoT、自洽性，或者特定要求模型的响应简洁明了。</p>
<p>下面是关于幻觉输出的系列论文和参考资料：</p>
<p>Survey of Hallucination in Natural Language Generation(Ji et al., 2022)</p>
<p>How Language Model Hallucinations Can Snowball(Zhang et al., 2023)</p>
<p>A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity(Bang et al., 2023)</p>
<p>Contrastive Learning Reduces Hallucination in Conversations(Sun et al., 2022)</p>
<p>Self-Consistency Improves Chain of Thought Reasoning in Language Models(Wang et al., 2022)</p>
<p>SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models(Manakul et al., 2023)</p>
<p>A simple example of fact-checking and hallucination by NVIDIA’s NeMo-Guardrails</p>
<h2 id="2优化上下文长度和上下文构建">2.优化上下文长度和上下文构建</h2>
<p>绝大部分问题都需要上下文。例如，如果我们问ChatGPT：“哪家越南餐厅最好？”所需的上下文将是“这个餐厅的限定范围到底在哪里？”，因为越南本土最好吃的餐厅与美国的最好吃的越南餐厅，这个问题的范围是不同的。</p>
<p>根据下面这篇很酷的论文《 SITUATEDQA: Incorporating Extra-Linguistic Contexts into QA 》（Zhang＆Choi，2021），有相当一部分信息搜索问题的答案与上下文有关，例如，在Natural Questions NQ-Open 数据集中大约占 16.5%。</p>
<p>（NQ-Open:https://ai.google.com/research/NaturalQuestions）</p>
<p>我个人认为，在企业实际遇到的案例中，这一比例会更高。例如，假设一家公司为客户支持建立了一个聊天机器人，要让这个聊天机器人回答客户关于任何产品的任何问题，所需的上下文很可能是该客户的历史或该产品的信息。由于语言模型会从提供给它的上下文中 &ldquo;学习&rdquo;，因此这一过程也被称为上下文学习。</p>
<p>图片客户支持查询所需的上下文</p>
<p>Context length 对于RAG（检索增强生成）非常重要，而RAG已成为大语言模型行业应用场景的主要模式。具体来说，检索增强生成主要分为两个阶段：</p>
<p><strong>第 1 阶段：分块（也称为编制索引）</strong> chunking (also known as indexing)</p>
<p>收集LLM使用的所有文档,将这些文档分成可以喂入大于模型，以生成嵌入的块，并将这些嵌入存储在向量数据库中。</p>
<p><strong>第2阶段：查询</strong></p>
<p>当用户发送查询时，如 &ldquo;我的保险单是否能够支付某种药物 X&rdquo;，大语言模型会将此查询转换为embedding，我们称之为 QUERY_EMBEDDING。向量数据库，会获取embedding与 QUERY_EMBEDDING 最相似的块。</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_4jdidmppa0.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p>上下文长度越长，我们就能在上下文中squeeze越多的chunks 。模型获取的信息越多，它的输出和回应质量就会越高，是这样的吗？</p>
<p>并非总是如此。模型能用多少上下文，和模型使用上下文的效率如何，是两个不同的问题。在努力增加模型上下文长度的同时，我们也在努力提高上下文的效率。有人称之为 &ldquo;提示工程prompt engineering &ldquo;或 &ldquo;prompt construction&rdquo;。例如，最近有一篇论文谈到了模型如何更好地理解索引开头和结尾，而不仅是中间的信息——Lost in the Middle: How Language Models Use Long Contexts (Liu et al., 2023).</p>
<h2 id="3-其他数据模式融入多模态">3. 其他数据模式融入（多模态）</h2>
<p>在我看来，多模态是非常强大的，但是它也同样被低估了。这里解释一下多模态的应用原因：</p>
<p>首先，许多具体应用场景都需要多模态数据，尤其是在医疗保健、机器人、电子商务、零售、游戏、娱乐等混合数据模态的行业。举例来说：</p>
<p>医疗检测通常需要文本（如医生笔记、患者问卷）和图像（如 CT、X 光片、核磁共振扫描片）。</p>
<p>产品的Metadata通常包含图片、视频、描述，甚至表格数据（如生产日期、重量、颜色），因为从需求角度，您可能会需要根据用户的评论或产品照片，自动填补缺失的产品信息，或者希望让用户能够使用形状或颜色等视觉信息，进行产品搜索。</p>
<p>其次，多模态有望大幅提升模型性能。一个既能理解文本又能理解图像的模型，难道不应该比单一能理解文本的模型表现更好吗？基于文本的模型，需要大量文本，以至于我们担心很快就会用完互联网数据来训练基于文本的模型。一旦文本耗尽，我们就需要利用其他数据模式。</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_gmzg2a2k8g.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p>让我特别兴奋的一个使用案例是，多模态技术可以让视障人士浏览互联网和浏览现实世界。</p>
<p>下面是关于多模态相关的系列论文和参考资料：</p>
<p>[CLIP] Learning Transferable Visual Models From Natural Language Supervision(OpenAI, 2021)</p>
<p>Flamingo: a Visual Language Model for Few-Shot Learning(DeepMind, 2022)</p>
<p>BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models(Salesforce, 2023)</p>
<p>KOSMOS-1: Language Is Not All You Need: Aligning Perception with Language Models(Microsoft, 2023)</p>
<p>PaLM-E: An embodied multimodal language model(Google, 2023)</p>
<p>LLaVA: Visual Instruction Tuning(Liu et al., 2023)</p>
<p>NeVA: NeMo Vision and Language Assistant (NVIDIA, 2023)</p>
<h2 id="4-让-llm-更快成本更低">4. 让 LLM 更快、成本更低</h2>
<p>当GPT-3.5在2022年11月底首次发布时，很多人对在生产中使用它的延迟和成本表示担忧。然而，自那时以来，延迟/成本分析已经迅速发生了变化。在不到半年的时间里，社区找到了一种方法，可以创建一个性能与GPT-3.5非常接近的模型，但所需的内存占用仅为GPT-3.5的2%左右。</p>
<p>这里的启示是：如果你创造出足够优秀的东西，人们会找到一种方法让它变得快速且经济高效。</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_nms3w7awrv.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p>以下是《Guanaco 7B》的性能数据，与ChatGPT GPT-3.5和GPT-4的性能进行了比较，根据《Guanco》论文中的报告。请注意：总体而言，下列关于性能的比较，离完美还差很远，并且，对LLM的评估非常非常困难。</p>
<p>Guanaco 7B 与 ChatGPT GPT-3.5 和 GPT-4 的性能比较：</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_jtz2jzcquf.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p>四年前，当我开始为《设计机器学习系统》一书撰写后来成为 &ldquo;模型压缩 &ldquo;部分的笔记时，我写了关于模型优化/压缩的四种主要技术：</p>
<blockquote>
<p>Quantization：迄今为止最通用的模型优化方法。量化通过使用较少的位数来表示模型的参数来减小模型的大小，例如，可以使用16位甚至4位来表示浮点数，而不是使用32位。</p>
<p>Knowledge distillation：一种通过训练小模型来模仿大型模型或模型集合的方法。</p>
<p>Low-rank factorization：这里的关键思路是用低维张量代替高维张量，以减少参数数量。例如，可以将 3x3 张量分解为 3x1 和 1x3 张量的乘积，这样就不再需要 9 个参数，而只需要 6 个参数。</p>
<p>Pruning<br>
所有上述四种技术在今天仍然适用和流行。Alpaca 采用Knowledge distillation进行训练。QLoRA 结合使用了Low-rank factorization和quantization。</p>
</blockquote>
<h2 id="5设计一种新的模型架构"><strong>5.设计一种新的模型架构</strong></h2>
<p>自 2012 年的 AlexNet 以来，我们看到了许多架构的兴衰，包括 LSTM、seq2seq 等。与这些相比，Transformer 的影响力，令人难以置信。自 2017 年以来，Transformer 就一直存在，而这种架构还能流行多久，还是个未解之谜。</p>
<p>开发一种新架构来超越 Transformer 并不容易。Transformer 在过去 6 年中进行了大量优化，而这种新架构，必须在人们当前关注的硬件，以当前关心的规模运行。</p>
<p>注意：谷歌最初设计 Transformer 是为了在 TPU 上快速运行，后来才在 GPU 上进行了优化。</p>
<p>2021 年，Chris Ré&rsquo;s lab的 S4 引起了广泛关注，详见《Efficiently Modeling Long Sequences with Structured State Spaces 》(Gu et al., 2021)）。Chris Ré&rsquo;s lab仍在大力开发新架构，最近与初创公司 Together 合作开发的架构 Monarch Mixer（Fu ，2023 年）就是其中之一。</p>
<p>他们的主要思路是，对于现有的 Transformer 架构，注意力的复杂度是序列长度的二次方，而 MLP 的复杂度是模型维度的二次方。具有次二次方复杂度的架构将更加高效。</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_sah7aku5zj.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p><em>Monarch Mixer</em></p>
<h2 id="6-开发-gpu-替代方案">6. 开发 GPU 替代方案</h2>
<p>自2012年的AlexNet以来，GPU一直是深度学习的主导硬件。实际上，AlexNet受欢迎的一个普遍认可的原因之一是它是首篇成功使用GPU来训练神经网络的论文。在GPU出现之前，如果想要以AlexNet的规模训练模型，需要使用数千个CPU，就像谷歌在AlexNet之前几个月发布的那款。与数千个CPU相比，几块GPU对于博士生和研究人员来说更加容易得到，从而引发了深度学习研究的繁荣。</p>
<p>在过去的十年里，许多公司，包括大型企业和创业公司，都试图为人工智能创建新的硬件。最值得注意的尝试包括谷歌的TPU、Graphcore的IPU（IPU的进展如何？）以及Cerebras。SambaNova筹集了超过十亿美元来开发新的AI芯片，但似乎已转向成为一个生成式AI平台。</p>
<p>有一段时间，人们对量子计算抱有很大的期望，其中关键参与者包括：</p>
<blockquote>
<p><em>IBM的QPU</em></p>
<p><em>谷歌的量子计算机在今年早些时候在《自然》杂志上报道了量子误差减少的重大里程碑。其量子虚拟机可以通过Google Colab公开访问。</em></p>
<p><em>研究实验室，如麻省理工学院量子工程中心、马克斯·普朗克量子光学研究所、芝加哥量子交流中心、奥克里奇国家实验室等。</em></p>
</blockquote>
<p>另一个同样令人兴奋的方向是光子芯片(photonic chips)。我对这个领域知之尚浅， 所以，如果有错误，请纠正我。现有芯片使用电力来传输数据，这消耗大量的能量并且产生延迟。而光子芯片使用光子来传输数据，利用光速进行更快、更高效的计算。在这个领域，各种初创公司已经融资数亿美元，包括Lightmatter（2.7亿美元）、Ayar Labs（2.2亿美元）、Lightelligence（2亿美元以上）和Luminous Computing（1.15亿美元）。</p>
<p>以下是光子矩阵计算三种主要方法的进展时间线，摘自论文《Photonic matrix multiplication lights up photonic accelerator and beyond》（Zhou，Nature 2022）。这三种不同的方法分别是平面光转换（PLC）、马赫-曾德尔干涉仪（MZI）和波分复用（WDM）。</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_b8udp9lf3a.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<h2 id="7-提高agents的可用性">7. 提高agents的可用性</h2>
<p>Agent指可以执行动作的大语言模型（可以理解为那些可以代替你来完成各种任务的代理人，所以叫Agent），例如浏览互联网、发送电子邮件、预订等。与本文中其他研究方向相比，这可能是最新的方向之一。由于Agent本身的新颖性和巨大潜力，人们对Agent充满热情。而Auto-GPT现在是GitHub上 标星数量排名第25的、最受欢迎的repo。GPT-Engineering是另一个受欢迎的repo。</p>
<p>尽管这个方向令人兴奋，但人们仍然对大语言模型是否足够可靠和高性能，以及能够被赋予行动的权力，存在疑虑。然而，已经出现了一个应用场景，即将Agent用于社会研究，例如著名的斯坦福实验，该实验显示一小簇生成式Agent产生了新兴的社会行为：例如，从一个用户指定的想法开始，一个Agent想要举办情人节派对，Agent在接下来的两天里自动传播派对的邀请，结交新朋友，互相邀请参加派对&hellip;（Generative Agents: Interactive Simulacra of Human Behavior, Park et al., 2023)，</p>
<p>在这个领域最值得注意的创业公司也许是Adept，由两位前Transformer的合著者和前OpenAI副总裁创立，到目前为止已经融资近5亿美元。去年，他们展示了他们的agent的如何浏览互联网的，还有就是演示了如何向Salesforce添加新账户。</p>
<h2 id="8-迭代rlhf">8. 迭代RLHF</h2>
<p>RLHF（从人类反馈中进行强化学习）很酷，但有点技巧性。如果人们找到更好的训练LLM的方法，也不奇怪。不过，在RLHF方面还存在许多未解决的问题，例如：</p>
<p>①如何用数学方式，表示人类偏好？</p>
<p>目前，人类偏好是通过比较来确定的：人类标注员确定响应A是否比响应B更好。然而，它没有考虑响应A比响应B好多少。</p>
<p>②什么是人类偏好(preference)？</p>
<p>Anthropic根据输出，在有益、诚实和无害三个方面对其模型的质量进行了衡量。请参阅Constitutional AI: Harmlessness from AI Feedback (Bai et al., 2022).</p>
<p>DeepMind试图生成能够取悦大多数人的响应。请参阅Fine-tuning language models to find agreement among humans with diverse preferences, (Bakker et al., 2022).</p>
<p>此外，我们想要能够表达立场的AI，还是对任何可能具有争议性的话题回避的传统AI呢？</p>
<p>③“人类”偏好究竟是谁的偏好，是否要考虑到文化、宗教、政治倾向等的差异？获得足够代表所有潜在用户的训练数据存在许多挑战。</p>
<p>例如，对于OpenAI的InstructGPT数据，没有65岁以上的标注员。标注员主要是菲律宾人和孟加拉人。请参阅InstructGPT: Training language models to follow instructions with human feedback (Ouyang et al., 2022).</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_uns4wh79cs.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p><em>InstructGPT标注员的国籍统计信息</em></p>
<p>尽管社区主导的努力在其意图上值得赞赏，但可能导致数据存在偏见。例如，对于OpenAssistant数据集，222位（90.5％）回答者中有201位自我认定为男性。Jeremy Howard在Twitter上有一个很好的Thread：</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_pbtcfitt0a.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<h2 id="9提高聊天界面效率">9.提高聊天界面效率</h2>
<p>自 ChatGPT 以来，人们一直在讨论聊天是否是一个适用于各种任务的界面。</p>
<p>详见：</p>
<p>Natural language is the lazy user interface(Austin Z. Henley, 2023)</p>
<p>Why Chatbots Are Not the Future(Amelia Wattenberger, 2023)</p>
<p>What Types of Questions Require Conversation to Answer? A Case Study of AskReddit Questions(Huang et al., 2023)</p>
<p>AI chat interfaces could become the primary user interface to read documentation(Tom Johnson, 2023)</p>
<p>Interacting with LLMs with Minimal Chat (Eugene Yan, 2023)</p>
<p>然而，这并不是一个新话题。在许多国家，尤其是在亚洲，聊天已经作为超级应用的界面使用了大约十年时间，Dan Grover在2014年就已经写过相关论文。</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_0ksz3tnyo3.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p>2016 年，当许多人认为应用程序已死、聊天机器人将成为未来时，讨论再次变得激烈紧张起来：</p>
<p>On chat as interface(Alistair Croll, 2016)</p>
<p>Is the Chatbot Trend One Big Misunderstanding?(Will Knight, 2016)</p>
<p>Bots won’t replace apps. Better apps will replace apps (Dan Grover, 2016)</p>
<p>我个人喜欢聊天界面，原因如下：</p>
<p>①聊天界面是每个人，甚至是没有先前接触过计算机或互联网的人，都可以迅速学会使用的界面（普适性）。在2010年代初，当我在肯尼亚的一个低收入居民区做志愿者时，我惊讶于那里的每个人在手机上进行银行业务时是多么熟悉，通过短信。那个社区没有人有计算机。</p>
<p>② 聊天界面是易于访问的。如果你的双手整忙于其他事情，可以使用语音而不是文本。</p>
<p>③ 聊天也是一个非常强大的界面&ndash;你可以向它提出任何请求，它都会给予回复，即使回复不一定完美</p>
<p>不过，笔者认为聊天界面在某些方面还可以继续改进：</p>
<p>①单次可交流多条消息</p>
<p>目前，我们基本上假设每次交流只有单轮消息。但这不是我和我的朋友发短信的方式。通常，我需要多条消息来完成我的思考，因为我需要插入不同的数据（例如图像、位置、链接），我可能在之前的消息中遗漏了某些内容，或者只是不想把所有内容都放在单一的大段落里。</p>
<p>②多模态输入</p>
<p>在多模态应用领域，大部分精力都花在构建更好的模型上，而很少花在构建更好的界面上。以Nvidia的NeVA聊天机器人为例。我不是用户体验专家，但我认为在这里可能有改进的空间。</p>
<p>附注：对这里提到NeVA团队表示抱歉，即使有了这个，你们的工作仍然非常酷！</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_sekqu09k0r.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p>③将生成式AI融入工作流程中</p>
<p>Linus Lee在他的分享“Generative AI interface beyond chats.”中很好地涵盖了这一点。例如，如果您想问关于您正在处理的图表中的某一列的问题，您应该能够只需指向那一列并提问。</p>
<p>④消息编辑和删除</p>
<p>用户输入的编辑或删除会如何改变与聊天机器人的对话流程？</p>
<h2 id="10-为非英语语言创建-llm">10. 为非英语语言创建 LLM</h2>
<p>我们知道，目前以英语为第一语言的 LLM 在性能、延迟和速度方面都无法很好地适用于许多其他语言。请参阅：</p>
<p>ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning(Lai et al., 2023)</p>
<p>All languages are NOT created (tokenized) equal (Yennie Jun, 2023)</p>
<p><img src="https://img.bibiqing.com/news/2023/0830/20_eq81h55qsr.png" alt="6000字解读：当前大语言模型LLM研究的10大挑战"></p>
<p>我只知道训练越南语的尝试（比如Symato 社区尝试），不过，本文几位早期读者告诉我，他们认为我不应该把这个方向包括进来，原因如下：</p>
<p>这与其说是一个研究问题，不如说是一个logistics问题。我们已经知道如何去做，只是需要有人投入资金和精力。不过，这并不完全正确。大多数语言都被认为是low-resource语言，例如，与英语或中文相比，很多语种的高质量数据要少得多，因此可能需要不同的技术来训练大型语言模型。参见：</p>
<p>Low-resource Languages: A Review of Past Work and Future Challenges(Magueresse et al., 2020)</p>
<p>JW300: A Wide-Coverage Parallel Corpus for Low-Resource Languages (Agić et al., 2019)</p>
<p>那些更为悲观的人认为，在未来，许多语言将会消失，互联网将由两个语言组成的两个宇宙：英语和汉语。这种思潮并不新鲜 - 有人还记得Esperanto吗？</p>
<p>人工智能工具，例如机器翻译和聊天机器人，对语言学习的影响仍然不明确。它们会帮助人们更快地学习新语言，还是会完全消除学习新语言的需求。</p>
<h2 id="结论">结论</h2>
<p>本文如有任何遗漏，请告知我，为了获取其他观点，请查阅这篇全面的论文《Challenges and Applications of Large Language Models (Kaddour et al., 2023).</p>
<p>上述问题比其他问题更加困难。例如，我认为上述第10个问题，即建立非英语语言的 LLM，只要有足够的时间和资源，就会比较简单。</p>
<p>上述第 1 个问题是减少幻觉输出，这将会难得多，因为幻觉只是 LLM 在做概率的事情。</p>
<p>第 4 ，让 LLM 更快、更便宜，这一点永远无法彻底解决。这方面已经取得了很大进展，以后还会有更多进展，但是这个方向的改进将会一直持续。</p>
<p>第 5 项和第 6 项，即新架构和新硬件，非常具有挑战性，但随着时间的推移，它们是不可避免的。由于架构和硬件之间的共生关系——新架构需要针对通用硬件进行优化，而硬件需要支持通用架构，它们可能会由同一家公司来完成。</p>
<p>有些问题仅靠技术知识是无法解决的。例如，第 8 个问题，即改进从人类偏好中学习的方法，可能更多的是一个政策问题，而不是技术问题。第 9 个问题是提高聊天界面的效率，这更像是用户体验问题。我们需要更多具有非技术背景的人员与我们一起解决这些问题。</p>
<p>你最感兴趣的研究方向是什么？认为最有希望解决这些问题的方案是什么？很想听听您的意见。</p>
<table>
    <thead>
        <tr>
            <th style="text-align:left">推荐平台</th>
            <th style="text-align:left">链接</th>
            <th style="text-align:left">平台介绍</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Gate芝麻开门</span></td>
            <td style="text-align:left"><span style="white-space:nowrap"><a
                        href="https://www.okbtc.cn/gateio?ref=githubio">平台介绍</a></span></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/gateio?ref=githubio">Gate.io芝麻开门创立于2013年，是全球真实交易量TOP10的加密货币交易平台，向全球数千万用户提供安全可靠、真实透明的数字资产交易服务。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bitget</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bitget?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bitget?ref=githubio">Bitget的背后是一群区块链技术的早期接受者，也是区块链未来发展的信仰者，一直致力于提供安全、一站式的交易解决方案，帮助用户更聪明地交易。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">Bybit</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/bybit?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/bybit?ref=githubio">Bybit通过数字资产与传统金融的结合，引领数字资产的生态发展。提供一流的流动性，致力于打造业内最安全、公平、高效及人性化的交易服务平台。</a>
            </td>
        </tr>
        <tr>
            <td style="text-align:left"><span style="white-space:nowrap">派网</span></td>
            <td style="text-align:left"><a href="https://www.okbtc.cn/pionex?ref=githubio">注册链接</a></td>
            <td style="text-align:left"><a
                    href="https://www.okbtc.cn/pionex?ref=githubio">派网提供多样化的量化交易机器人，用户可依照自身交易需求和策略选择最适合的机器人。 同时派网也提供合约交易与合约网格机器人，给予更方便的合约交易体验。</a>
            </td>
        </tr>
    </tbody>
</table>

        </div>

        
        



        
        


        <footer class="post-footer">
          


          
          <nav class="post-nav">
            
              <a class="prev" href="/post/58170/">
                
                <i class="iconfont">
                  <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

                </i>
                <span class="prev-text nav-default">专访Bitget Builders：熊市之下如何成为加密共建者?</span>
                <span class="prev-text nav-mobile">上一篇</span>
              </a>
            
              <a class="next" href="/post/58037/">
                <span class="next-text nav-default">AI攻入客服</span>
                <span class="prev-text nav-mobile">下一篇</span>
                
                <i class="iconfont">
                  <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

                </i>
              </a>
          </nav>
        </footer>
      </article>

      
      
        
      


      
      


    </div>

    
    <nav class="toc" id="toc">
    <div class="toc-title">文章目录</div>
    <div class="toc-content custom-scrollbar">
      <nav id="TableOfContents">
  <ul>
    <li><a href="#1-减少和评估幻觉">1. 减少和评估幻觉</a></li>
    <li><a href="#2优化上下文长度和上下文构建">2.优化上下文长度和上下文构建</a></li>
    <li><a href="#3-其他数据模式融入多模态">3. 其他数据模式融入（多模态）</a></li>
    <li><a href="#4-让-llm-更快成本更低">4. 让 LLM 更快、成本更低</a></li>
    <li><a href="#5设计一种新的模型架构"><strong>5.设计一种新的模型架构</strong></a></li>
    <li><a href="#6-开发-gpu-替代方案">6. 开发 GPU 替代方案</a></li>
    <li><a href="#7-提高agents的可用性">7. 提高agents的可用性</a></li>
    <li><a href="#8-迭代rlhf">8. 迭代RLHF</a></li>
    <li><a href="#9提高聊天界面效率">9.提高聊天界面效率</a></li>
    <li><a href="#10-为非英语语言创建-llm">10. 为非英语语言创建 LLM</a></li>
    <li><a href="#结论">结论</a></li>
  </ul>
</nav>
    </div>
  </nav>


  </div>

      </main>

      <footer id="footer" class="footer">
        <div class="icon-links">
  

<a href="https://www.okbtc.cn/binance?ref=githubio" class="iconfont">
  <img src="/image/logo/binance.png" width="36px" height="36px" alt="binance">
</a>

<a href="https://www.okbtc.cn/okx?ref=githubio" class="iconfont">
  <img src="/image/logo/okx.png" width="36px" height="36px" alt="okx">
</a>

<a href="https://www.okbtc.cn/htx?ref=githubio" class="iconfont">
  <img src="/image/logo/htx.png" width="36px" height="36px" alt="htx">
</a>

<a href="https://www.okbtc.cn/gateio?ref=githubio" class="iconfont">
  <img src="/image/logo/gateio.png" width="36px" height="36px" alt="gateio">
</a>

<a href="https://www.okbtc.cn/bitget?ref=githubio" class="iconfont">
  <img src="/image/logo/bitget.png" width="36px" height="36px" alt="bitget">
</a>

<a href="https://www.okbtc.cn/bybit?ref=githubio" class="iconfont">
  <img src="/image/logo/bybit.png" width="36px" height="36px" alt="bybit">
</a>

<a href="https://www.okbtc.cn/pionex?ref=githubio" class="iconfont">
  <img src="/image/logo/pionex.png" width="36px" height="36px" alt="pionex">
</a>



</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    2023
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        coin
        
      </span></span>

  
  

  
</div>

      </footer>

      <div class="button__back-to-top">
        <a href="#back-to-top">
          <i class="iconfont">
            
            <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

          </i>
        </a>
      </div>
    </div>
    
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.5e8c82c5ae3f71b40f78c4ff8ea351326a65ddf5771f76c10c6fc7d09808332d.js" integrity="sha256-XoyCxa4/cbQPeMT/jqNRMmpl3fV3H3bBDG/H0JgIMy0=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  











<script>
  var remark_config = {
    host: 'https:\/\/remark42.example.com',
    site_id: 'remark',
    components: [
	    'embed',
    ],
  }
  !function(e,n){for(var o=0;o<e.length;o++){var r=n.createElement("script"),c=".js",d=n.head||n.body;"noModule"in r?(r.type="module",c=".mjs"):r.async=!0,r.defer=!0,r.src=remark_config.host+"/web/"+e[o]+c,d.appendChild(r)}}(remark_config.components||["embed"],document);
</script>







  </body>
</html>
